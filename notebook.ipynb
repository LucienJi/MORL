{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jijingtian/anaconda3/envs/morl/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from algorithm.ppo import Learner\n",
    "from configs.args_parser import Parameters\n",
    "from configs import Factor_dictionary\n",
    "from algorithm.analysis import MO_Analysis\n",
    "from algorithm.utils import MO_Stats\n",
    "# import mo_gymnasium as mo_gym \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n",
    "import os\n",
    "import io\n",
    "env_id = 'minecart-v0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def constant_init(module, val, bias=0):\n",
    "    if hasattr(module, 'weight') and module.weight is not None:\n",
    "        nn.init.constant_(module.weight, val)\n",
    "    if hasattr(module, 'bias') and module.bias is not None:\n",
    "        nn.init.constant_(module.bias, bias)\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    trainable block and locked block\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim,output_dim,hidden_size = [512, 512]):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        fc_linear = []\n",
    "        fc_linear.append(nn.Linear(input_dim,hidden_size[0]))\n",
    "        fc_linear.append(nn.Tanh())\n",
    "        for i in range(len(hidden_size) - 1):\n",
    "            fc_linear.append(nn.Linear(hidden_size[i],hidden_size[i+1]))\n",
    "            fc_linear.append(nn.Tanh())\n",
    "        self.fc_linear = nn.Sequential(*fc_linear)\n",
    "        self.last_dim = hidden_size[-1]\n",
    "        self.last_layer = nn.Linear(hidden_size[-1],output_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc_linear(x)\n",
    "        x = self.last_layer(x)\n",
    "        return x\n",
    "\n",
    "class ControlBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    contain two block, one is locked, one is trainable\n",
    "    contain two zero layer\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim,feature_dim,output_dim,hidden_size = [512,512],allow_retrain = False):\n",
    "        super().__init__()\n",
    "        #! trainable and locked block must has the same size \n",
    "        self.trainable_block = Block(input_dim,output_dim,hidden_size)\n",
    "        self.locked_block = Block(input_dim,output_dim,hidden_size)\n",
    "\n",
    "        ##TODO 改动1： zero layer 需要 state or style 的信息\n",
    "        self.zero_layer1 = nn.Sequential(\n",
    "            nn.Linear(feature_dim + input_dim,hidden_size[0]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size[0],input_dim)\n",
    "        )\n",
    "        self.zero_layer2 = nn.Sequential(\n",
    "            nn.Linear(output_dim + feature_dim,hidden_size[0]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size[0],output_dim)\n",
    "        )\n",
    "        self.allow_retrain = allow_retrain\n",
    "        self.init()\n",
    "        self._set_parameter()\n",
    "    def _set_parameter(self):\n",
    "        for p in self.trainable_block.parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in self.locked_block.parameters():\n",
    "            p.requires_grad = self.allow_retrain\n",
    "\n",
    "    def init(self):\n",
    "        for m in self.modules():\n",
    "            if m in (self.zero_layer1,self.zero_layer2):\n",
    "                constant_init(m,val=0.0)\n",
    "\n",
    "    def forward(self,x,extra_input):\n",
    "        input1 = torch.cat([x,extra_input],dim = 1)\n",
    "        delta_x = self.zero_layer1(input1)\n",
    "        x_ = x + delta_x\n",
    "        y_ = self.trainable_block.forward(x_)\n",
    "        input2 = torch.cat([y_,extra_input],dim = 1)\n",
    "        delta_y = self.zero_layer2(input2)\n",
    "        return self.trainable_block(x) + delta_y\n",
    "    def load_expert_state_dict(self,state_dict):\n",
    "        self.locked_block.load_state_dict(state_dict)\n",
    "        self.trainable_block.load_state_dict(state_dict)\n",
    "        with torch.no_grad():\n",
    "            for p in self.trainable_block.parameters():\n",
    "                p.requires_grad = True\n",
    "        with torch.no_grad():\n",
    "            for p in self.locked_block.parameters():\n",
    "                p.requires_grad = self.allow_retrain\n",
    "\n",
    "class ExpertNet(nn.Module):\n",
    "    def __init__(self, state_dim, style_dim, num_acts):\n",
    "        super(ExpertNet,self).__init__()\n",
    "        self.state_encoder = nn.Linear(state_dim, 512)\n",
    "        self.block1 = Block(512,512,hidden_size=[512,512])\n",
    "\n",
    "        self.policy_block = Block(512,256,hidden_size=[512,512])\n",
    "        self.value_block = Block(512,256,hidden_size=[512,512])\n",
    "\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, num_acts)\n",
    "        )\n",
    "\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def init(self):\n",
    "        for m in self.modules():\n",
    "            if m in (self.policy_head, self.value_head):\n",
    "                for sub_m in m:\n",
    "                    if isinstance(sub_m, (nn.Conv2d, nn.Linear)):\n",
    "                        nn.init.orthogonal(sub_m.weight)\n",
    "            elif m in (self.state_encoder,self.block1,self.policy_block,self.value_block):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "    def forward(self, state, ma):\n",
    "        # ma: action mask: 1 means invalid!!\n",
    "        state_ = state[:, :-6]\n",
    "        style = state[:, -6:]\n",
    "        state_emb = self.state_encoder(state_)\n",
    "\n",
    "        mid = self.block1(state_emb)\n",
    "        policy_mid = self.policy_block(mid)\n",
    "        value_mid = self.value_block(mid)\n",
    "\n",
    "        policy_out = self.policy_head(policy_mid)\n",
    "        y = policy_out.masked_fill(ma, -np.inf)\n",
    "        probs = self.softmax(y - y.max(1)[0].unsqueeze(1))\n",
    "        log_probs = F.log_softmax(y, dim=1)\n",
    "        value = self.value_head(value_mid)\n",
    "        return probs, log_probs, value\n",
    "    \n",
    "    def save_expert_state_dict(self):\n",
    "        expert_state = {\n",
    "            \"state_encoder_state_dict\": self.state_encoder.state_dict(),\n",
    "            \"block1_state_dict\": self.block1.state_dict(),\n",
    "            \"policy_block_state_dict\": self.policy_block.state_dict(),\n",
    "            \"value_block_state_dict\": self.value_block.state_dict(),\n",
    "            \"policy_head_state_dict\": self.policy_head.state_dict(),\n",
    "            \"value_head_state_dict\": self.value_head.state_dict(),\n",
    "        }\n",
    "        return expert_state \n",
    "\n",
    "class  PolicyNet(nn.Module):\n",
    "    def __init__(self,state_dim, style_dim, num_acts,allow_retrain=False):\n",
    "        super(PolicyNet,self).__init__()\n",
    "        #! Encoder: state style\n",
    "        self.state_encoder = nn.Linear(state_dim, 512)\n",
    "        self.style_encoder = nn.Linear(style_dim,512)\n",
    "\n",
    "        self.block1 = ControlBlock(512,512,512,[512,512],allow_retrain=allow_retrain)\n",
    "\n",
    "        self.policy_block = ControlBlock(512,512,256,[512,512],allow_retrain=allow_retrain)\n",
    "        self.value_block = ControlBlock(512,512,256,[512,512],allow_retrain=allow_retrain)\n",
    "\n",
    "        self.policy_head = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, num_acts)\n",
    "        )\n",
    "\n",
    "        self.value_head = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def init(self):\n",
    "        for m in self.modules():\n",
    "            if m in (self.policy_head, self.value_head):\n",
    "                for sub_m in m:\n",
    "                    if isinstance(sub_m, (nn.Conv2d, nn.Linear)):\n",
    "                        nn.init.orthogonal(sub_m.weight)\n",
    "            elif m in (self.state_encoder,self.style_encoder):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "    \n",
    "    def forward(self,state, ma):\n",
    "        # ma: action mask: 1 means invalid!!\n",
    "        state_ = state[:, :-6]\n",
    "        style = state[:, -6:]\n",
    "        state_emb = self.state_encoder(state_)\n",
    "        style_emb = self.style_encoder(style)\n",
    "\n",
    "        mid = self.block1.forward(state_emb, style_emb)\n",
    "        policy_mid = self.policy_block.forward(mid, style_emb)\n",
    "        value_mid = self.value_block.forward(mid, style_emb)\n",
    "\n",
    "        policy_out = self.policy_head(policy_mid)\n",
    "        y = policy_out.masked_fill(ma, -np.inf)\n",
    "        probs = self.softmax(y - y.max(1)[0].unsqueeze(1))\n",
    "        log_probs = F.log_softmax(y, dim=1)\n",
    "        value = self.value_head(value_mid)\n",
    "        return probs, log_probs, value\n",
    "    \n",
    "    def load_expert_state_dict(self,state_dict:dict):\n",
    "        #! allow retrain \n",
    "        if 'state_encoder_state_dict' in state_dict.keys():\n",
    "            self.state_encoder.load_state_dict(state_dict['state_encoder_state_dict'])\n",
    "        if 'policy_head_state_dict' in state_dict.keys():\n",
    "            self.policy_head.load_state_dict(state_dict['policy_head_state_dict'])\n",
    "        if 'value_head_state_dict' in state_dict.keys():\n",
    "            self.value_head.load_state_dict(state_dict['value_head_state_dict'])\n",
    "        if 'block1_state_dict' in state_dict.keys():\n",
    "            self.block1.load_expert_state_dict(state_dict['block1_state_dict'])\n",
    "        if 'policy_block_state_dict' in state_dict.keys():\n",
    "            self.policy_block.load_expert_state_dict(state_dict['policy_block_state_dict'])\n",
    "        if 'value_block_state_dict' in state_dict.keys():\n",
    "            self.value_block.load_expert_state_dict(state_dict['value_block_state_dict'])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = PolicyNet(20,6,4)\n",
    "expert = ExpertNet(20,6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_jit = torch.jit.script(expert)\n",
    "mas_jit = torch.jit.script(mas)\n",
    "torch.jit.save(expert_jit, 'tmp/expert_jit')\n",
    "torch.jit.save(mas_jit, 'tmp/mas_jit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_state_dict = expert.save_expert_state_dict()\n",
    "mas.load_expert_state_dict(expert_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(expert_state_dict, 'tmp/expert_state_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "\n",
    "model_files = glob.glob('tmp/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = torch.load(model_files[-1])\n",
    "mas.load_expert_state_dict(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "morl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
